{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLKWSPqpUhQk"
      },
      "source": [
        "## Pre Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIRL1b2_UhQm",
        "outputId": "dcc3c7a1-b090-4bb8-e2fd-7867991a46dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n"
          ]
        }
      ],
      "source": [
        "pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_O65dxgwUhQn"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eq63azsIUhQn"
      },
      "source": [
        "## Data Scraping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02jw3WDoUhQo"
      },
      "source": [
        "This cell is responsible for scraping mobile phone data from a specified website. It begins by importing the necessary libraries, `requests` for handling HTTP requests and `BeautifulSoup` for parsing HTML content. The base URL of the website is set up, and an empty list `extractedLinks` is initialized to store the URLs of individual mobile phone pages.\n",
        "\n",
        "A function `scrapePage(pageNum)` is defined to handle the process of fetching and parsing each page. It sends a request to the website for a given page, checks if the request was successful, and then parses the HTML content. If phone listings are found on the page, the function extracts the URL for each phone by navigating through specific HTML elements.\n",
        "\n",
        "The script then iterates through 371 pages, calling `scrapePage` for each one and printing the current page number being processed. Once all pages are processed, it prints the total number of links extracted. This forms the basis for collecting URLs to be used in the next stages of data gathering.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmH-U2AQQB4w",
        "outputId": "15c225e8-c3b6-4807-92c6-8f53d637abf3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Scraping pages: 100%|██████████| 371/371 [05:06<00:00,  1.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Total links extracted: 7317\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "baseUrl = \"https://www.gadgets360.com/mobiles/phone-finder?page={}\"\n",
        "extractedLinks = []\n",
        "\n",
        "def scrapePage(pageNum):\n",
        "    url = baseUrl.format(pageNum)\n",
        "    response = requests.get(url)\n",
        "\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Failed to retrieve page {pageNum}\")\n",
        "        return\n",
        "\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    allPlistDiv = soup.find('div', id='allplist')\n",
        "\n",
        "    if allPlistDiv:\n",
        "        phoneDivs = allPlistDiv.find_all('div', class_='_lpdwgt _flx pdbtlinks')\n",
        "\n",
        "        for phoneDiv in phoneDivs:\n",
        "            innerDivWrapper = phoneDiv.find('div', class_='_flx _lpbwg')\n",
        "\n",
        "            if innerDivWrapper:\n",
        "                innerDivs = innerDivWrapper.find_all('div')\n",
        "\n",
        "                if len(innerDivs) >= 2:\n",
        "                    secondDiv = innerDivs[1]\n",
        "                    h3Tag = secondDiv.find('h3')\n",
        "\n",
        "                    if h3Tag:\n",
        "                        aTag = h3Tag.find('a')\n",
        "\n",
        "                        if aTag and 'href' in aTag.attrs:\n",
        "                            link = aTag['href']\n",
        "                            extractedLinks.append(link)\n",
        "\n",
        "for page in tqdm(range(1, 372), desc=\"Scraping pages\"):\n",
        "    scrapePage(page)\n",
        "\n",
        "print(f\"\\n\\nTotal links extracted: {len(extractedLinks)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rh3w3NyUhQo"
      },
      "source": [
        "This cell is dedicated to scraping the detailed specifications of each mobile phone using the URLs collected in the previous step. It starts by defining an empty list, `phoneSpecsList`, which will store the specifications of each phone.\n",
        "\n",
        "The `scrapePhoneSpecs(phoneUrl)` function is defined to handle the process of extracting details from each phone’s page. It sends a request to the provided URL and, if successful, parses the HTML to locate the main specifications section. The function then iterates through each category of specifications, gathering attribute names and values, and adds them to a dictionary `phoneSpecs` with uniquely formatted keys to maintain clarity across categories.\n",
        "\n",
        "The script then loops through each link in `extractedLinks`, calls `scrapePhoneSpecs` for each phone URL, and stores the extracted data in `phoneSpecsList`. It also tracks and accumulates all unique feature names found across the pages. For each phone, it prints the number of features extracted and the growing total of unique features. Once all phone specifications are processed, it prints the total count of phones scraped.\n",
        "\n",
        "This cell effectively gathers and structures detailed specification data for each phone, preparing it for further analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBNHr-Kvu33B",
        "outputId": "08815847-14b8-41c1-8cd3-d48a3c192635"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Scraping specs from links: 100%|██████████| 7317/7317 [1:23:54<00:00,  1.45it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Total phones scraped: 7317\n",
            "\n",
            "Total features extracted: 118\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "phoneSpecsList = []\n",
        "\n",
        "def scrapePhoneSpecs(phoneUrl):\n",
        "    response = requests.get(phoneUrl)\n",
        "\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Failed to retrieve phone details at {phoneUrl}\")\n",
        "        return {}\n",
        "\n",
        "    decodedContent = response.text.encode(\"utf-8\",errors=\"ignore\").decode(\"utf-8\")\n",
        "\n",
        "    soup = BeautifulSoup(decodedContent, 'html.parser')\n",
        "\n",
        "    specsDiv = soup.find('div', id='specs')\n",
        "\n",
        "    phoneSpecs = {}\n",
        "\n",
        "    if not specsDiv:\n",
        "        print(\"No specs found for mobile \" + phoneUrl)\n",
        "        return {}\n",
        "\n",
        "    for div in specsDiv.find_all('div'):\n",
        "        div1 = div.find('div')\n",
        "\n",
        "        if not div1:\n",
        "            continue\n",
        "\n",
        "        div2 = div1.find('div')\n",
        "        if not div2:\n",
        "            continue\n",
        "\n",
        "        generalName = div2.text\n",
        "        table = div.find('table')\n",
        "\n",
        "        if not table:\n",
        "            print(\"No specs table found under category \" + generalName)\n",
        "\n",
        "        rows = table.find('tbody').find_all('tr')\n",
        "        tempGeneralName = generalName\n",
        "\n",
        "        for row in rows:\n",
        "            tds = row.find_all('td')\n",
        "\n",
        "            if len(tds) > 2:\n",
        "                print(\"Length greater than 2 for the phone \" + phoneUrl + \" under the specs \" + generalName)\n",
        "                continue\n",
        "\n",
        "            if len(tds) == 1:\n",
        "                tempGeneralName = f\"{generalName}_{tds[0].text.strip()}\"\n",
        "                continue\n",
        "\n",
        "            attributeName = tds[0].text.strip()\n",
        "            attributeValue = tds[1].text.strip()\n",
        "            key = f\"{tempGeneralName}_{attributeName}\"\n",
        "            phoneSpecs[key] = attributeValue\n",
        "\n",
        "    return phoneSpecs\n",
        "\n",
        "i = 1\n",
        "features = set()\n",
        "\n",
        "for link in tqdm(extractedLinks, desc=\"Scraping specs from links\"):\n",
        "        phoneSpecs = scrapePhoneSpecs(link)\n",
        "        features.update(phoneSpecs.keys())\n",
        "\n",
        "        phoneSpecsList.append(phoneSpecs)\n",
        "        i += 1\n",
        "\n",
        "print(f\"\\n\\nTotal phones scraped: {len(phoneSpecsList)}\")\n",
        "print(f\"\\nTotal features extracted: {len(features)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHLLoUvHUhQp"
      },
      "source": [
        "## Data creation and Loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_vJPQFWUhQp"
      },
      "source": [
        "This cell converts the list of phone specifications, `phoneSpecsList`, into a pandas DataFrame, `df`. Each element of `phoneSpecsList` corresponds to the specifications of a single phone, and the DataFrame is structured such that each row represents one phone, with columns for each unique specification attribute.\n",
        "\n",
        "After creating the DataFrame, the cell saves the data to a CSV file named `phone_data.csv`, excluding the index column. This CSV file contains all the scraped phone specifications, making it easy to store and later analyze the data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wuncD6Fm98kX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(phoneSpecsList)\n",
        "\n",
        "df.to_csv('phone_data.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYYJQl19UhQq"
      },
      "source": [
        "This cell loads the previously saved `phone_data.csv` file into a pandas DataFrame, `df`. The data from the CSV file, which contains the scraped phone specifications, is read back into the notebook, making it available for further analysis and processing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "QGOlUc892rBD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "df = pd.read_csv('phone_data.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTq6kA5wUhQq"
      },
      "source": [
        "This cell prints the dimensions of the DataFrame `df`, displaying the number of rows and columns in the dataset. It uses `df.shape` to retrieve the shape of the DataFrame, where `df.shape[0]` represents the number of rows (i.e., the number of phones) and `df.shape[1]` represents the number of columns (i.e., the number of specification attributes). This helps to quickly understand the size of the dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGIUPO0VwP1m",
        "outputId": "dfaf7da7-c8c5-44f7-df01-56d69d1fb45b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 7303 rows in the dataset with 118 columns\n"
          ]
        }
      ],
      "source": [
        "print(f\"There are {df.shape[0]} rows in the dataset with {df.shape[1]} columns\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GAOLlgeUhQq"
      },
      "source": [
        "## Data cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8Ln1-AdUhQq"
      },
      "source": [
        "This cell checks for missing values in the DataFrame `df`. It uses the `isnull()` method to identify any null or missing entries in each column and then applies `sum()` to count the number of missing values per column. The result is converted to a dictionary format, where the keys are column names, and the values represent the count of missing values in each corresponding column. This allows for a quick assessment of data completeness.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7FHlU2C5aWT",
        "outputId": "8e209869-a8a4-4c75-8441-4f91fbce8963"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'General_Brand': 2,\n",
              " 'General_Model': 2,\n",
              " 'General_Price in India': 2682,\n",
              " 'General_Release date': 285,\n",
              " 'General_Launched in India': 4658,\n",
              " 'General_Dimensions (mm)': 1579,\n",
              " 'General_Weight (g)': 2203,\n",
              " 'General_IP rating': 6896,\n",
              " 'General_Battery capacity (mAh)': 207,\n",
              " 'General_Removable battery': 2204,\n",
              " 'General_Fast charging': 5491,\n",
              " 'General_Colours': 1569,\n",
              " 'Display_Refresh Rate': 6272,\n",
              " 'Display_Screen size (inches)': 64,\n",
              " 'Display_Touchscreen': 169,\n",
              " 'Display_Resolution': 617,\n",
              " 'Display_Protection type': 6616,\n",
              " 'Display_Pixels per inch (PPI)': 5059,\n",
              " 'Hardware_Processor': 685,\n",
              " 'Hardware_Processor make': 2046,\n",
              " 'Hardware_RAM': 638,\n",
              " 'Hardware_Internal storage': 494,\n",
              " 'Hardware_Expandable storage': 1018,\n",
              " 'Camera_Rear camera': 22,\n",
              " 'Camera_No. of Rear Cameras': 5758,\n",
              " 'Camera_Front camera': 77,\n",
              " 'Camera_No. of Front Cameras': 5797,\n",
              " 'Software_Operating system': 326,\n",
              " 'Software_Skin': 4371,\n",
              " 'Connectivity_Wi-Fi': 170,\n",
              " 'Connectivity_Wi-Fi standards supported': 3287,\n",
              " 'Connectivity_Bluetooth': 149,\n",
              " 'Connectivity_USB Type-C': 5193,\n",
              " 'Connectivity_Number of SIMs': 834,\n",
              " 'Connectivity_Active 4G on both SIM cards': 6466,\n",
              " 'Connectivity_SIM 1_SIM Type': 2587,\n",
              " 'Connectivity_SIM 1_GSM/CDMA': 2540,\n",
              " 'Connectivity_SIM 1_3G': 2489,\n",
              " 'Connectivity_SIM 1_4G/ LTE': 2432,\n",
              " 'Connectivity_SIM 1_5G': 6746,\n",
              " 'Connectivity_SIM 1_Supports 4G in India (Band 40)': 2912,\n",
              " 'Connectivity_SIM 2_SIM Type': 2705,\n",
              " 'Connectivity_SIM 2_GSM/CDMA': 2625,\n",
              " 'Connectivity_SIM 2_3G': 2544,\n",
              " 'Connectivity_SIM 2_4G/ LTE': 2476,\n",
              " 'Connectivity_SIM 2_5G': 6880,\n",
              " 'Connectivity_SIM 2_Supports 4G in India (Band 40)': 3015,\n",
              " 'General_Form factor': 720,\n",
              " 'Connectivity_NFC': 2051,\n",
              " 'Connectivity_Infrared': 3076,\n",
              " 'Display_Resolution Standard': 6466,\n",
              " 'Display_Aspect ratio': 5676,\n",
              " 'Hardware_Expandable storage type': 1912,\n",
              " 'Hardware_Expandable storage up to (GB)': 2303,\n",
              " 'Camera_Rear autofocus': 5594,\n",
              " 'Camera_Rear flash': 1517,\n",
              " 'Connectivity_GPS': 560,\n",
              " 'Connectivity_Headphones': 2004,\n",
              " 'Connectivity_FM': 2620,\n",
              " 'Sensors_Fingerprint sensor': 5317,\n",
              " 'Sensors_Compass/ Magnetometer': 1424,\n",
              " 'Sensors_Proximity sensor': 701,\n",
              " 'Sensors_Accelerometer': 670,\n",
              " 'Sensors_Ambient light sensor': 794,\n",
              " 'Sensors_Gyroscope': 1558,\n",
              " 'General_Wireless charging': 6587,\n",
              " 'Sensors_In-Display Fingerprint Sensor': 6659,\n",
              " 'Sensors_Face unlock': 6166,\n",
              " 'Hardware_Dedicated microSD slot': 6498,\n",
              " 'Camera_Pop-Up Camera': 6820,\n",
              " 'Connectivity_Wi-Fi Direct': 3058,\n",
              " 'Sensors_Barometer': 3118,\n",
              " 'Connectivity_USB OTG': 2632,\n",
              " 'Camera_Lens Type (Second Rear Camera)': 7154,\n",
              " 'Camera_Lens Type (Third Rear Camera)': 7183,\n",
              " 'Camera_Front autofocus': 7091,\n",
              " 'Camera_Front flash': 6495,\n",
              " 'Sensors_3D face recognition': 7196,\n",
              " 'General_Body type': 6868,\n",
              " 'General_Brand Exclusive Features': 7278,\n",
              " 'Camera_Lens Type (Fourth Rear Camera)': 7301,\n",
              " 'Connectivity_Lightning': 7145,\n",
              " 'General_Wireless Charging Type': 7288,\n",
              " 'Sensors_Temperature sensor': 3309,\n",
              " 'Connectivity_Wi-Fi 7': 7295,\n",
              " 'General_Thickness': 7169,\n",
              " 'Connectivity_SIM Type': 6456,\n",
              " 'Connectivity_3G': 6312,\n",
              " 'Connectivity_4G/ LTE': 6310,\n",
              " 'Connectivity_Micro-USB': 6621,\n",
              " 'Second display_Screen size (inches)': 7219,\n",
              " 'Second display_Touchscreen': 7223,\n",
              " 'Second display_Resolution': 7230,\n",
              " 'Second display_Protection type': 7288,\n",
              " 'Second display_Pixels per inch (PPI)': 7269,\n",
              " 'General_SAR value': 6990,\n",
              " 'Connectivity_Mobile High-Definition Link (MHL)': 3337,\n",
              " 'Connectivity_GSM/CDMA': 6346,\n",
              " 'Connectivity_Supports 4G in India (Band 40)': 6340,\n",
              " 'General_Alternate names': 6868,\n",
              " 'Third display_Protection type': 7302,\n",
              " 'Camera_Rear third camera attr': 7278,\n",
              " 'Second display_Aspect ratio': 7296,\n",
              " 'Connectivity_5G': 7289,\n",
              " 'General_Height': 7300,\n",
              " 'Camera_Lens Type (Primary Rear Camera)': 7302,\n",
              " 'General_Width': 7293,\n",
              " 'Connectivity_SIM 3_SIM Type': 7293,\n",
              " 'Connectivity_SIM 3_3G': 7295,\n",
              " 'Connectivity_SIM 3_4G/ LTE': 7295,\n",
              " 'Connectivity_SIM 3_Supports 4G in India (Band 40)': 7295,\n",
              " 'General_Price in India (Expected)': 7291,\n",
              " 'Connectivity_SIM 3_GSM/CDMA': 7296,\n",
              " 'Third display_Screen size (inches)': 7302,\n",
              " 'Third display_Touchscreen': 7302,\n",
              " 'Third display_Resolution': 7302,\n",
              " 'Camera_Lens Type (Secondary Front Camera)': 7300,\n",
              " 'Camera_Lens Type (Front Camera)': 7302}"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dict(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKI6iODOUhQq"
      },
      "source": [
        "This cell handles missing values in the `General_Removable battery` column of the DataFrame `df`. It uses the `fillna()` method to replace any null or missing entries in this specific column with the string `'Unknown'`. This ensures that all rows in the column have a value, preventing issues that might arise from missing data during analysis or model training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "vnGNNXnv60E3"
      },
      "outputs": [],
      "source": [
        "df.loc[:,'General_Removable battery'] = df['General_Removable battery'].fillna('Unknown')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4m019IDUhQr"
      },
      "source": [
        "This cell addresses missing values in the `Connectivity_NFC` column of the DataFrame `df`. Similar to the previous cell, it uses the `fillna()` method to replace any null or missing entries in this column with the string `'Unknown'`. This ensures that the column has no missing values, making the dataset more complete for further analysis or modeling.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "JrcM4BtG_DZ6"
      },
      "outputs": [],
      "source": [
        "df.loc[:,'Connectivity_NFC'] = df['Connectivity_NFC'].fillna('Unknown')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDS4HRuWUhQr"
      },
      "source": [
        "This cell drops a large number of columns from the DataFrame `df`. The specified columns are removed as they may not be relevant for the analysis or model training, or they may contain redundant or non-essential information. The `drop()` method is used with the `inplace=True` argument to modify the DataFrame directly. The `errors='ignore'` argument ensures that no error is raised if any of the specified columns are not found in the DataFrame. This step helps in reducing the dataset's size and focuses on the most useful features for further analysis or modeling.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "TvKse_QaQYvS"
      },
      "outputs": [],
      "source": [
        "df.drop(columns=[\n",
        "    'General_Launched in India',\n",
        "    'General_IP rating',\n",
        "    'Display_Touchscreen',\n",
        "    'Display_Protection type',\n",
        "    'Display_Pixels per inch (PPI)',\n",
        "    'Camera_No. of Rear Cameras',\n",
        "    'Camera_No. of Front Cameras',\n",
        "    'Software_Skin',\n",
        "    'Connectivity_Wi-Fi',\n",
        "    'Connectivity_Wi-Fi standards supported',\n",
        "    'Connectivity_USB Type-C',\n",
        "    'Connectivity_Active 4G on both SIM cards',\n",
        "    'Connectivity_SIM 1_SIM Type',\n",
        "    'Connectivity_SIM 1_Supports 4G in India (Band 40)',\n",
        "    'Connectivity_SIM 1_GSM/CDMA',\n",
        "    'Connectivity_SIM 2_SIM Type',\n",
        "    'Connectivity_SIM 2_GSM/CDMA',\n",
        "    'Connectivity_SIM 2_Supports 4G in India (Band 40)',\n",
        "    'General_Form factor',\n",
        "    'Connectivity_Infrared',\n",
        "    'Display_Aspect ratio',\n",
        "    'Hardware_Expandable storage type',\n",
        "    'Camera_Rear autofocus',\n",
        "    'Camera_Rear flash',\n",
        "    'Connectivity_GPS',\n",
        "    'Connectivity_FM',\n",
        "    'Sensors_Fingerprint sensor',\n",
        "    'Sensors_Compass/ Magnetometer',\n",
        "    'Sensors_Proximity sensor',\n",
        "    'Sensors_Accelerometer',\n",
        "    'Sensors_Ambient light sensor',\n",
        "    'Sensors_Gyroscope',\n",
        "    'General_Wireless charging',\n",
        "    'Sensors_In-Display Fingerprint Sensor',\n",
        "    'Sensors_Face unlock',\n",
        "    'Hardware_Dedicated microSD slot',\n",
        "    'Camera_Pop-Up Camera',\n",
        "    'Connectivity_Wi-Fi Direct',\n",
        "    'Sensors_Barometer',\n",
        "    'Connectivity_USB OTG',\n",
        "    'Camera_Lens Type (Second Rear Camera)',\n",
        "    'Camera_Lens Type (Third Rear Camera)',\n",
        "    'Camera_Front autofocus',\n",
        "    'Camera_Front flash',\n",
        "    'Sensors_3D face recognition',\n",
        "    'General_Body type',\n",
        "    'General_Brand Exclusive Features',\n",
        "    'Camera_Lens Type (Fourth Rear Camera)',\n",
        "    'Connectivity_Lightning',\n",
        "    'General_Wireless Charging Type',\n",
        "    'Sensors_Temperature sensor',\n",
        "    'Connectivity_Wi-Fi 7',\n",
        "    'General_Thickness',\n",
        "    'Connectivity_SIM Type',\n",
        "    'Connectivity_3G',\n",
        "    'Connectivity_4G/ LTE',\n",
        "    'Connectivity_Micro-USB',\n",
        "    'Second display_Screen size (inches)',\n",
        "    'Second display_Touchscreen',\n",
        "    'Second display_Resolution',\n",
        "    'Second display_Protection type',\n",
        "    'Second display_Pixels per inch (PPI)',\n",
        "    'General_SAR value',\n",
        "    'Connectivity_Mobile High-Definition Link (MHL)',\n",
        "    'Connectivity_GSM/CDMA',\n",
        "    'Connectivity_Supports 4G in India (Band 40)',\n",
        "    'General_Alternate names',\n",
        "    'Third display_Protection type',\n",
        "    'Camera_Rear third camera attr',\n",
        "    'Second display_Aspect ratio',\n",
        "    'Connectivity_5G',\n",
        "    'General_Height',\n",
        "    'Camera_Lens Type (Primary Rear Camera)',\n",
        "    'General_Width',\n",
        "    'Connectivity_SIM 3_SIM Type',\n",
        "    'Connectivity_SIM 3_3G',\n",
        "    'Connectivity_SIM 3_4G/ LTE',\n",
        "    'Connectivity_SIM 3_Supports 4G in India (Band 40)',\n",
        "    'General_Price in India (Expected)',\n",
        "    'Connectivity_SIM 3_GSM/CDMA',\n",
        "    'Third display_Screen size (inches)',\n",
        "    'Third display_Touchscreen',\n",
        "    'Third display_Resolution',\n",
        "    'Camera_Lens Type (Secondary Front Camera)',\n",
        "    'Camera_Lens Type (Front Camera)',\n",
        "    'General_Dimensions (mm)',\n",
        "    'General_Fast charging',\n",
        "    'General_Colours',\n",
        "    'Display_Resolution',\n",
        "    'Display_Resolution Standard',\n",
        "    'Connectivity_Headphones',\n",
        "    'Hardware_Processor',\n",
        "    'Connectivity_Bluetooth',\n",
        "    'Connectivity_Number of SIMs',\n",
        "    'Hardware_Expandable storage up to (GB)',\n",
        "    'General_Weight (g)',\n",
        "    'Hardware_Processor make',\n",
        "    'General_Model',\n",
        "    'Software_Operating system',\n",
        "    'General_Brand'\n",
        "    ],\n",
        "    inplace=True,\n",
        "    errors='ignore'\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tj95qStCUhQr"
      },
      "source": [
        "This cell processes the `General_Release date` column in the DataFrame `df`. It applies a lambda function to each value in the column to ensure a consistent format for the release year. For each non-null value, the function extracts the last two digits of the year and prefixes them with \"20\" (e.g., converting \"22\" to \"2022\"). If the value is null, it assigns 'Unknown' as the release date. This step standardizes the year format and handles missing values appropriately.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "Wj1CQYYbJn_g"
      },
      "outputs": [],
      "source": [
        "df.loc[:,'General_Release date'] = df['General_Release date'].apply(\n",
        "    lambda x: \"20\" + str(x)[-2:] if pd.notnull(x) else 'Unknown'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49WHqudmUhQr"
      },
      "source": [
        "This cell fills any missing values in the `Display_Refresh Rate` column of the DataFrame `df` with the default value `'60 Hz'`. It uses the `fillna()` method to replace null entries, ensuring that all rows in this column have a value. This step ensures consistency in the dataset by handling missing data for display refresh rates.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "ayRFWxlnKYs2"
      },
      "outputs": [],
      "source": [
        "df.loc[:,'Display_Refresh Rate'] = df['Display_Refresh Rate'].fillna('60 Hz')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzBkLrgNUhQs"
      },
      "source": [
        "This cell fills any missing values in the `Hardware_Expandable storage` column of the DataFrame `df` with the string `'Unknown'`. The `fillna()` method is used to replace null or missing entries, ensuring that all rows in this column have a value. This step helps in maintaining a complete dataset by handling missing data for expandable storage information.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "LxcpI4TlMSjl"
      },
      "outputs": [],
      "source": [
        "df.loc[:,'Hardware_Expandable storage'] = df['Hardware_Expandable storage'].fillna('Unknown')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "as_-Da3NUhQs"
      },
      "source": [
        "This cell processes the `Camera_Rear camera` column in the DataFrame `df` to extract and standardize camera information. The `processCameraInfo()` function splits the camera details by the '+' symbol and searches for megapixel values using regular expressions. It then stores the megapixel values of up to five cameras in separate columns (`camera_1_megapixel`, `camera_2_megapixel`, etc.). If fewer than five cameras are mentioned, it fills the remaining columns with zeros. Additionally, the total number of cameras is recorded in the `num_cameras` column. This ensures the camera information is structured in a consistent format for further analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "wWd6be9zkWTh"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def processCameraInfo(cameraInfo):\n",
        "    if pd.isna(cameraInfo):\n",
        "        return [0, 0, 0, 0, 0, 0]\n",
        "    cameras = cameraInfo.split('+')\n",
        "\n",
        "    megapixels = []\n",
        "    for cam in cameras:\n",
        "        match = re.search(r'(\\d+)-megapixel', cam)\n",
        "        if match:\n",
        "            megapixels.append(int(match.group(1)))\n",
        "    while len(megapixels) < 5:\n",
        "        megapixels.append(0)\n",
        "    megapixels.append(len(cameras))\n",
        "    return megapixels\n",
        "\n",
        "cameraFeatures = df['Camera_Rear camera'].apply(processCameraInfo)\n",
        "df[['camera_1_megapixel', 'camera_2_megapixel', 'camera_3_megapixel', 'camera_4_megapixel', 'camera_5_megapixel', 'num_cameras']] = pd.DataFrame(cameraFeatures.tolist(), index=df.index)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXexkPOtUhQs"
      },
      "source": [
        "This cell processes the `Camera_Front camera` column in the DataFrame `df` to extract and standardize front camera information. The `processFrontCameraInfo()` function splits the front camera details by the '+' symbol and searches for megapixel values using regular expressions. It then stores the megapixel values of up to two front cameras in separate columns (`front_camera_1_megapixel`, `front_camera_2_megapixel`). If fewer than two cameras are mentioned, it fills the remaining columns with zeros. Additionally, the total number of front cameras is recorded in the `num_front_cameras` column. This standardizes the front camera details into a consistent format for further analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "3lOLBq9plySf"
      },
      "outputs": [],
      "source": [
        "def processFrontCameraInfo(cameraInfo):\n",
        "    if pd.isna(cameraInfo):\n",
        "        return [0, 0, 0]\n",
        "    cameras = cameraInfo.split('+')\n",
        "\n",
        "    megapixels = []\n",
        "    for cam in cameras:\n",
        "        match = re.search(r'(\\d+)-megapixel', cam)\n",
        "        if match:\n",
        "            megapixels.append(int(match.group(1)))\n",
        "    while len(megapixels) < 2:\n",
        "        megapixels.append(0)\n",
        "    megapixels.append(len(cameras))\n",
        "    return megapixels\n",
        "\n",
        "cameraFeatures = df['Camera_Front camera'].apply(processFrontCameraInfo)\n",
        "df[['front_camera_1_megapixel', 'front_camera_2_megapixel', 'num_front_cameras']] = pd.DataFrame(cameraFeatures.tolist(), index=df.index)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wg-yN21sUhQt"
      },
      "source": [
        "This cell processes the network connectivity details for two SIM cards (`SIM 1` and `SIM 2`) in the DataFrame `df`. The function `getHighestNetwork()` determines the highest available network type for each SIM based on the availability of 5G, 4G, or 3G networks. It prioritizes 5G, followed by 4G, and then 3G. The resulting highest network type for each SIM is stored in two new columns: `Network_SIM_1` and `Network_SIM_2`. The `apply()` function is used to apply this logic row-wise across the relevant columns for both SIMs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "jV5mxqearcj-"
      },
      "outputs": [],
      "source": [
        "def getHighestNetwork(sim3G, sim4G, sim5G):\n",
        "    if pd.notna(sim5G):\n",
        "        return '5G'\n",
        "    elif pd.notna(sim4G):\n",
        "        return '4G'\n",
        "    elif pd.notna(sim3G):\n",
        "        return '3G'\n",
        "    else:\n",
        "        return 'Unknown'\n",
        "\n",
        "df['Network_SIM_1'] = df.apply(\n",
        "    lambda row: getHighestNetwork(row['Connectivity_SIM 1_3G'],\n",
        "                                   row['Connectivity_SIM 1_4G/ LTE'],\n",
        "                                   row['Connectivity_SIM 1_5G']),\n",
        "    axis=1)\n",
        "\n",
        "df['Network_SIM_2'] = df.apply(\n",
        "    lambda row: getHighestNetwork(row['Connectivity_SIM 2_3G'],\n",
        "                                   row['Connectivity_SIM 2_4G/ LTE'],\n",
        "                                   row['Connectivity_SIM 2_5G']),\n",
        "    axis=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPtTaeXFUhQt"
      },
      "source": [
        "This cell drops several columns from the DataFrame `df` that are no longer needed after the processing steps. The columns removed include:\n",
        "- Connectivity details for both `SIM 1` and `SIM 2` networks (3G, 4G, and 5G).\n",
        "- Camera information for both the rear and front cameras.\n",
        "\n",
        "The `inplace=True` argument ensures that the changes are applied directly to the DataFrame, modifying it without the need to assign the result back to a new variable.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "PA8vG7L3sfVB"
      },
      "outputs": [],
      "source": [
        "df.drop(\n",
        "    columns=[\n",
        "        'Connectivity_SIM 1_3G',\n",
        "        'Connectivity_SIM 1_4G/ LTE',\n",
        "        'Connectivity_SIM 1_5G',\n",
        "        'Connectivity_SIM 2_3G',\n",
        "        'Connectivity_SIM 2_4G/ LTE',\n",
        "        'Connectivity_SIM 2_5G',\n",
        "        'Camera_Rear camera',\n",
        "        'Camera_Front camera'\n",
        "    ],\n",
        "    inplace=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuhMeIHkUhQy"
      },
      "source": [
        "This line of code processes the `General_Price in India` column in the DataFrame `df`. It performs the following steps:\n",
        "\n",
        "1. **Stripping the currency symbol**: The `.str[1:]` removes the first character of the string, the currency symbol (e.g., \"₹\").\n",
        "2. **Removing commas**: The `.replace(\",\",\"\",regex=True)` removes any commas in the price value (e.g., \"1,00,000\" becomes \"100000\").\n",
        "3. **Converting to numeric**: The `.apply(pd.to_numeric, errors='coerce')` converts the cleaned price string into a numeric type (integer or float). If a value cannot be converted to a number, it is coerced to `NaN`.\n",
        "\n",
        "This results in a numeric column of prices in India, with any non-convertible values replaced by `NaN`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "LZvkAVKar61_"
      },
      "outputs": [],
      "source": [
        "df.loc[:,'General_Price in India'] = df['General_Price in India'].str[1:].replace(\",\",\"\",regex=True).apply(pd.to_numeric, errors='coerce')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.loc[:,'General_Battery capacity (mAh)'] = df['General_Battery capacity (mAh)'].str.replace(\",\",\"\",regex=True).replace(\"mAh\",\"\",regex=True).apply(pd.to_numeric, errors='coerce')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.loc[:,'General_Release date'] = df['General_Release date'].apply(pd.to_numeric, errors='coerce')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-XfR-i_UhQy"
      },
      "source": [
        "This line of code fills any missing values (NaNs) in the `General_Price in India` column with the mean of the non-missing values in that column. Here's a breakdown:\n",
        "\n",
        "1. **Handling missing values**: The `.fillna()` function is used to replace any missing (`NaN`) values in the `General_Price in India` column.\n",
        "2. **Calculating the mean**: `df['General_Price in India'].mean()` computes the mean (average) of the values in the `General_Price in India` column, excluding `NaN` values.\n",
        "3. **Filling missing values**: The missing values are replaced with the calculated mean.\n",
        "\n",
        "This ensures that the column has no missing values and that any missing price data is replaced with the average price from the rest of the dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNv0n1cWtkfW",
        "outputId": "2f9ba133-fec0-460f-87bf-8cce23473e2a"
      },
      "outputs": [],
      "source": [
        "df.loc[:,'General_Price in India'] = df['General_Price in India'].fillna(df['General_Price in India'].mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeaqJwyVUhQz"
      },
      "source": [
        "This line of code fills any missing values (NaNs) in the `General_Battery capacity (mAh)` column with the most frequent value (mode) in that column. Here's a breakdown:\n",
        "\n",
        "1. **Handling missing values**: The `.fillna()` function is used to replace any missing (`NaN`) values in the `General_Battery capacity (mAh)` column.\n",
        "2. **Calculating the mode**: `df['General_Battery capacity (mAh)'].mode()[0]` computes the mode, which is the most frequent value in the `General_Battery capacity (mAh)` column. The `[0]` is used to extract the first mode value if there are multiple modes.\n",
        "3. **Filling missing values**: The missing values are replaced with the most frequent value.\n",
        "\n",
        "This ensures that the column has no missing values and that any missing battery capacity data is replaced with the most common battery capacity from the rest of the dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "s2BmBE5jvK-8"
      },
      "outputs": [],
      "source": [
        "df.loc[:,'General_Battery capacity (mAh)'] = df['General_Battery capacity (mAh)'].fillna(df['General_Battery capacity (mAh)'].mode()[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4Z4KsfpUhQz"
      },
      "source": [
        "This line of code fills any missing values (NaNs) in the `Display_Screen size (inches)` column with the most frequent value (mode) in that column. Here's a breakdown:\n",
        "\n",
        "1. **Handling missing values**: The `.fillna()` function is used to replace any missing (`NaN`) values in the `Display_Screen size (inches)` column.\n",
        "2. **Calculating the mode**: `df['Display_Screen size (inches)'].mode()[0]` computes the mode, which is the most frequent value in the `Display_Screen size (inches)` column. The `[0]` is used to extract the first mode value if there are multiple modes.\n",
        "3. **Filling missing values**: The missing values are replaced with the most frequent value.\n",
        "\n",
        "This ensures that the column has no missing values and that any missing screen size data is replaced with the most common screen size from the rest of the dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "CzXPNFIPvW7b"
      },
      "outputs": [],
      "source": [
        "df.loc[:,'Display_Screen size (inches)'] = df['Display_Screen size (inches)'].fillna(df['Display_Screen size (inches)'].mode()[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGI4MTqMUhQz"
      },
      "source": [
        "This line of code fills any missing values (NaNs) in the `Hardware_Internal storage` column with the most frequent value (mode) in that column. Here's a breakdown:\n",
        "\n",
        "1. **Handling missing values**: The `.fillna()` function is used to replace any missing (`NaN`) values in the `Hardware_Internal storage` column.\n",
        "2. **Calculating the mode**: `df['Hardware_Internal storage'].mode()[0]` computes the mode, which is the most frequent value in the `Hardware_Internal storage` column. The `[0]` is used to extract the first mode value if there are multiple modes.\n",
        "3. **Filling missing values**: The missing values are replaced with the most frequent value.\n",
        "\n",
        "This ensures that the column has no missing values and that any missing internal storage data is replaced with the most common internal storage size from the rest of the dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "1HrxVWBdvdNE"
      },
      "outputs": [],
      "source": [
        "df.loc[:,'Hardware_Internal storage'] = df['Hardware_Internal storage'].fillna(df['Hardware_Internal storage'].mode()[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYiCDXS2UhQz"
      },
      "source": [
        "This line removes any rows in the dataframe `df` that contain missing values (`NaN`). After executing this command, only the rows with complete data will remain in the dataframe, which is useful when you want to ensure no missing values for further analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "q8ouNIl6vq7o"
      },
      "outputs": [],
      "source": [
        "df = df.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4B8uJd5fUhQ0"
      },
      "source": [
        "This line checks for any missing values (`NaN`) in the dataframe `df`. It returns a dictionary where the keys are the column names, and the values are the count of missing values in each column. This helps to quickly identify which columns still have missing data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8yOzw6H-IZv",
        "outputId": "1e729901-1ea6-41e2-8307-480434455a33"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'General_Price in India': 0,\n",
              " 'General_Release date': 0,\n",
              " 'General_Battery capacity (mAh)': 0,\n",
              " 'General_Removable battery': 0,\n",
              " 'Display_Refresh Rate': 0,\n",
              " 'Display_Screen size (inches)': 0,\n",
              " 'Hardware_RAM': 0,\n",
              " 'Hardware_Internal storage': 0,\n",
              " 'Hardware_Expandable storage': 0,\n",
              " 'Connectivity_NFC': 0,\n",
              " 'camera_1_megapixel': 0,\n",
              " 'camera_2_megapixel': 0,\n",
              " 'camera_3_megapixel': 0,\n",
              " 'camera_4_megapixel': 0,\n",
              " 'camera_5_megapixel': 0,\n",
              " 'num_cameras': 0,\n",
              " 'front_camera_1_megapixel': 0,\n",
              " 'front_camera_2_megapixel': 0,\n",
              " 'num_front_cameras': 0,\n",
              " 'Network_SIM_1': 0,\n",
              " 'Network_SIM_2': 0}"
            ]
          },
          "execution_count": 115,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dict(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YCa5UpZUhQ1"
      },
      "source": [
        "This line prints a message displaying the current number of rows and columns in the dataframe `df` after preprocessing. It uses `df.shape[0]` to get the number of rows and `df.shape[1]` to get the number of columns. The output will be in the format: \"There are now {number_of_rows} rows in the dataframe with {number_of_columns} columns.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4X0M9Zathp3",
        "outputId": "afe8c6fa-02d9-43d5-98e1-f42d2f603db5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are now 6420 rows in the dataframe with 21 columns\n"
          ]
        }
      ],
      "source": [
        "print(f\"There are now {df.shape[0]} rows in the dataframe with {df.shape[1]} columns\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgq-U572UhQ1"
      },
      "source": [
        "This line of code removes the \" Hz\" suffix from the `Display_Refresh Rate` column values and converts them into integers. It first uses `str.replace(' Hz', '', regex=False)` to strip the \" Hz\" part from the values, and then `.astype(int)` converts the result to integers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "8ylY5WG-xiA9"
      },
      "outputs": [],
      "source": [
        "df.loc[:, 'Display_Refresh Rate'] = df['Display_Refresh Rate'].str.replace(' Hz', '', regex=False).astype(int)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "he1JzzR_UhQ2"
      },
      "source": [
        "This block of code defines a function `extractMostValue` that processes storage and RAM values from strings like \"64 GB\", \"128 MB\", or \"1 TB\". Inside, it defines a helper function `convertToGb` that converts any given value to gigabytes (GB). The `convertToGb` function handles the conversion for values in TB, GB, or MB by checking the suffix and adjusting the number accordingly. It then applies the `extractMostValue` function to the `Hardware_Internal storage` and `Hardware_RAM` columns of the DataFrame, converting each value to its equivalent in GB and retaining the maximum value for each row.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "ZeuNwikrzdTX"
      },
      "outputs": [],
      "source": [
        "def extractMostValue(values):\n",
        "    def convertToGb(value):\n",
        "        num = float(value[:-2].strip())\n",
        "        suffix = value[-2:].strip()\n",
        "\n",
        "        if suffix == 'TB':\n",
        "            return num * 1024\n",
        "        elif suffix == 'GB':\n",
        "            return num\n",
        "        elif suffix == 'MB':\n",
        "            return num / 1024\n",
        "        return 0\n",
        "\n",
        "    numsInGb = [convertToGb(val) for val in values.split(',')]\n",
        "    return max(numsInGb)\n",
        "\n",
        "df.loc[:,'Hardware_Internal storage'] = df['Hardware_Internal storage'].apply(extractMostValue)\n",
        "df.loc[:,'Hardware_RAM'] = df['Hardware_RAM'].apply(extractMostValue)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7R86z8cUhQ2"
      },
      "source": [
        "This line of code reorders the columns in the DataFrame by excluding the column `General_Price in India` from the list of columns and then appending it to the end. This is done by creating a list comprehension that iterates over all column names in the DataFrame (`df.columns`), filtering out `General_Price in India`, and then concatenating it at the end. This effectively moves the `General_Price in India` column to the last position.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "DxQZlYnI495j"
      },
      "outputs": [],
      "source": [
        "df = df[[col for col in df.columns if col != 'General_Price in India'] + ['General_Price in India']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeFUWVvPUhQ2"
      },
      "source": [
        "This line of code saves the cleaned and transformed DataFrame `df` to a CSV file named `phone_data_final.csv`. The `index=False` argument ensures that the index of the DataFrame is not included in the output CSV file, keeping only the data and the column names.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "9lg2cvfwvuIM"
      },
      "outputs": [],
      "source": [
        "df.to_csv('phone_data_final.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTg64J85UhQ3"
      },
      "source": [
        "The code snippet above imports necessary libraries for data processing and machine learning tasks. It reads the data from `phone_data_final.csv` and separates the features (`x`) and target (`y`). The target variable is `General_Price in India`, while the remaining columns serve as features. Then, it splits the dataset into training and test sets, with 20% of the data used for testing, and sets a random seed (`random_state=42`) to ensure reproducibility.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "xn7sv-j7wz9h"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "import numpy as np\n",
        "\n",
        "data = pd.read_csv('phone_data_final.csv')\n",
        "\n",
        "x = data.drop('General_Price in India', axis=1)\n",
        "y = data['General_Price in India']\n",
        "\n",
        "xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFyUYRFNUhQ3"
      },
      "source": [
        "This code performs one-hot encoding on the training (`xTrain`) and testing (`xTest`) feature sets using `pd.get_dummies`, dropping the first category to avoid multicollinearity. The training and testing sets are then aligned to ensure both have the same columns. If any column is missing in the test set, it is filled with zeros using the `fill_value=0` parameter. This ensures that both feature sets are compatible for model training and testing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "FxycJqVOIx03"
      },
      "outputs": [],
      "source": [
        "xTrainFinal = pd.get_dummies(xTrain, drop_first=True)\n",
        "xTestFinal = pd.get_dummies(xTest, drop_first=True)\n",
        "\n",
        "xTrainFinal, xTestFinal = xTrainFinal.align(xTestFinal, join='left', axis=1, fill_value=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWQV3CSkUhQ3"
      },
      "source": [
        "This code uses the `MinMaxScaler` to scale the feature sets. The `fit_transform` method is applied to the training data (`xTrainFinal`) to compute the scaling parameters and apply the transformation, while the `transform` method is applied to the test data (`xTestFinal`) to scale it using the same parameters. Scaling ensures that the features are on the same scale, which can improve the performance of certain machine learning models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "G2CAR1rMX9uh"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler()\n",
        "xTrainScaled = scaler.fit_transform(xTrainFinal)\n",
        "xTestScaled = scaler.transform(xTestFinal)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPOEhEn3UhQ3"
      },
      "source": [
        "This code evaluates three different regression models: `RandomForestRegressor`, `SupportVectorRegressor`, and `DecisionTreeRegressor` on the scaled training data. For each model, the following steps are performed:\n",
        "\n",
        "- The model is trained using the training data (`xTrainScaled` and `yTrain`).\n",
        "- Predictions are made on the test data (`xTestScaled`).\n",
        "- The model's performance is evaluated using:\n",
        "  - **Mean Absolute Error (MAE)**: Measures the average absolute difference between predicted and actual values.\n",
        "  - **Root Mean Squared Error (RMSE)**: Measures the square root of the average squared differences between predicted and actual values.\n",
        "  - **R-squared (R2)**: Indicates the proportion of variance in the target variable explained by the model.\n",
        "\n",
        "The results for each model (MAE, RMSE, R2 Score) are printed out to compare their performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_features=&#x27;sqrt&#x27;, n_estimators=500)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_features=&#x27;sqrt&#x27;, n_estimators=500)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "RandomForestRegressor(max_features='sqrt', n_estimators=500)"
            ]
          },
          "execution_count": 127,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = RandomForestRegressor(n_estimators=500, max_features=\"sqrt\")\n",
        "\n",
        "model.fit(xTrainScaled,yTrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3J_W6MBAX_AL",
        "outputId": "ecfe682e-c5ee-45a8-8284-dd8a42ca96d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RandomForestRegressor:\n",
            "  Mean Absolute Error: 4769.56\n",
            "  RMSE: 10320.94\n",
            "  R2 Score: 0.51\n",
            "\n",
            "SupportVectorRegressor:\n",
            "  Mean Absolute Error: 5794.05\n",
            "  RMSE: 14474.73\n",
            "  R2 Score: 0.03\n",
            "\n",
            "DecisionTreeRegressor:\n",
            "  Mean Absolute Error: 5783.18\n",
            "  RMSE: 13605.15\n",
            "  R2 Score: 0.15\n",
            "\n"
          ]
        }
      ],
      "source": [
        "models = {\n",
        "    \"RandomForestRegressor\": RandomForestRegressor(n_estimators=500,max_features=\"sqrt\"),\n",
        "    \"SupportVectorRegressor\": SVR(C=10),\n",
        "    \"DecisionTreeRegressor\": DecisionTreeRegressor(max_depth=20)\n",
        "}\n",
        "\n",
        "for modelName, model in models.items():\n",
        "    model.fit(xTrainScaled, yTrain)\n",
        "    yPred = model.predict(xTestScaled)\n",
        "\n",
        "    mae = mean_absolute_error(yTest, yPred)\n",
        "    rmse = np.sqrt(mean_squared_error(yTest, yPred))\n",
        "    r2 = r2_score(yTest, yPred)\n",
        "\n",
        "    print(f\"{modelName}:\")\n",
        "    print(f\"  Mean Absolute Error: {mae:.2f}\")\n",
        "    print(f\"  RMSE: {rmse:.2f}\")\n",
        "    print(f\"  R2 Score: {r2:.2f}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ER0_-UL1UhQ4"
      },
      "source": [
        "### Findings and Conclusion:\n",
        "\n",
        "1. **Best Performing Model: RandomForestRegressor**  \n",
        "   The **RandomForestRegressor** is the best performing model in this analysis, with the **lowest Mean Absolute Error (MAE)** of 4195.06 and **Root Mean Squared Error (RMSE)** of 8882.37. It also achieved an **R2 Score of 0.53**, meaning it explains 53% of the variance in the target variable (price in India).  \n",
        "\n",
        "   The reason behind its superior performance lies in its ability to capture complex relationships in the data through multiple decision trees and its ability to generalize better compared to the other models.\n",
        "\n",
        "2. **Weakest Performing Model: SupportVectorRegressor**  \n",
        "   The **SupportVectorRegressor** performed poorly, with a **very high MAE** (5689.58) and **RMSE** (12720.84). Its **R2 Score** of only 0.03 indicates that it explained nearly none of the variance in the target variable.  \n",
        "\n",
        "   This could be due to the model's sensitivity to the feature scaling and the difficulty in capturing the complex relationships in the data with the chosen hyperparameters (C=10). The support vector machine model tends to struggle when the data is noisy or when the features are not well suited for the model's assumptions.\n",
        "\n",
        "3. **DecisionTreeRegressor: Moderate Performance**  \n",
        "   The **DecisionTreeRegressor** performed reasonably well with a **MAE** of 4802.34, **RMSE** of 10769.87, and an **R2 Score** of 0.30. While it showed a moderate ability to capture patterns in the data, it still fell short of the RandomForestRegressor.  \n",
        "\n",
        "   A potential reason for its lower performance is its tendency to overfit the training data, leading to poorer generalization on unseen test data. Additionally, the model’s performance can be heavily impacted by hyperparameter tuning, especially the depth of the tree.\n",
        "\n",
        "### Final Conclusion:\n",
        "The **RandomForestRegressor** is the most suitable model for predicting phone prices in India based on this dataset, as it strikes a good balance between accuracy and generalization. It should be prioritized for further fine-tuning and deployment. The **DecisionTreeRegressor** may also be considered if simpler models are preferred, though further optimization would be required. The **SupportVectorRegressor** underperformed significantly and should likely be excluded from consideration for this task.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "yozcAUpNpogk"
      },
      "outputs": [],
      "source": [
        "df.to_csv(\"cleaned_phone_data.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['model.pkl']"
            ]
          },
          "execution_count": 131,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(scaler, \"scaler.pkl\")\n",
        "\n",
        "# Save the trained Random Forest model\n",
        "joblib.dump(model, \"model.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
